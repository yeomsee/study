{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2463,"status":"ok","timestamp":1729344999284,"user":{"displayName":"염시형","userId":"10102578423005698819"},"user_tz":-540},"id":"nZ6mMrKjg6bW","outputId":"c7f693ba-bc8c-4b05-b3ec-2b9c2bdd3002"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJv9FOGvhn6D"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import (DataLoader, TensorDataset)\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_swE2azg8CZ"},"outputs":[],"source":["class SpacingRNN(nn.Module):\n","    def __init__(self, config):\n","        super(SpacingRNN, self).__init__()\n","\n","        # 음절 -> idx\n","        self.eumjeol_vocab_size = config['eumjeol_vocab_size']\n","        self.embedding_size = config['embedding_size']\n","        self.hidden_size = config['hidden_size']\n","        self.number_of_labels = config['number_of_labels'] # label의 수 = 3\n","\n","        self.embedding = nn.Embedding(num_embeddings=self.eumjeol_vocab_size, embedding_dim=self.embedding_size, padding_idx=0)\n","\n","        self.dropout = nn.Dropout(config['dropout'])\n","\n","        self.bi_lstm = nn.LSTM(input_size=self.embedding_size, hidden_size=self.hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n","\n","        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_labels)\n","        self.linear = nn.Linear(in_features=self.hidden_size*2, out_features=self.number_of_labels)\n","\n","    def forward(self, inputs):\n","        # (batch_size, max_length) -> (batch_size, max_length, embedding_size)\n","        eumjeol_inputs = self.embedding(inputs)\n","\n","        hidden_outputs, hidden_states = self.bi_lstm(eumjeol_inputs)\n","\n","        # (batch_size, max_length, hidden_size*2)\n","        hidden_outputs = self.dropout(hidden_outputs)\n","\n","        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_labels)\n","        hypothesis = self.linear(hidden_outputs)\n","\n","        return hypothesis"]},{"cell_type":"markdown","metadata":{"id":"6nWGwQQBkvGp"},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HO0w3y8slNPM"},"outputs":[],"source":["def read_datas(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as inFile:\n","        lines = inFile.readlines()\n","\n","    datas = []\n","    for line in lines:\n","        pieces = line.strip().split('\\t')\n","        eumjeol_sequence, label_sequence = pieces[0].split(), pieces[1].split()\n","        datas.append((eumjeol_sequence, label_sequence))\n","    return datas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oflYBEFhmN-3"},"outputs":[],"source":["def read_vocab_data(eumjeol_vocab_data_path):\n","    label2idx, idx2label = {\"<PAD>\": 0, \"B\": 1, \"I\": 2}, {0: \"PAD\", 1: \"B\", 2: \"I\"}\n","    eumjeol2idx, idx2eumjeol = {}, {}\n","\n","    with open(eumjeol_vocab_data_path, 'r', encoding='utf-8') as inFile:\n","        lines = inFile.readlines()\n","\n","    for line in lines:\n","        eumjeol = line.strip()\n","        eumjeol2idx[eumjeol] = len(eumjeol2idx)\n","        idx2eumjeol[eumjeol2idx[eumjeol]] = eumjeol\n","\n","    return eumjeol2idx, idx2eumjeol, label2idx, idx2label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nRisiTjnV1z"},"outputs":[],"source":["def load_dataset(config):\n","    datas = read_datas(config[\"input_data\"])\n","    eumjeol2idx, idx2eumjeol, label2idx, idx2label = read_vocab_data(config[\"eumjeol_vocab\"])\n","\n","    eumjeol_features, eumjeol_feature_lengths, label_features = [], [], []\n","\n","    for eumjeol_sequence, label_sequence in datas:\n","        eumjeol_feature = [eumjeol2idx[eumjeol] for eumjeol in eumjeol_sequence]\n","        label_feature = [label2idx[label] for label in label_sequence]\n","\n","        eumjeol_feature_length = len(eumjeol_feature)\n","\n","        eumjeol_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n","        label_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n","\n","        eumjeol_features.append(eumjeol_feature)\n","        eumjeol_feature_lengths.append(eumjeol_feature_length)\n","        label_features.append(label_feature)\n","\n","    eumjeol_features = torch.tensor(eumjeol_features, dtype=torch.long)\n","    eumjeol_feature_lengths = torch.tensor(eumjeol_feature_lengths, dtype=torch.long)\n","    label_features = torch.tensor(label_features, dtype=torch.long)\n","\n","    return eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol,label2idx, idx2label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPQkgWSLnspK"},"outputs":[],"source":["def train(config):\n","    model = SpacingRNN(config).cuda()\n","\n","    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol,label2idx, idx2label = load_dataset(config)\n","\n","    train_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n","    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config['batch_size'])\n","\n","    loss_func = nn.CrossEntropyLoss(ignore_index=0)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    for epoch in range(config[\"epoch\"]):\n","        model.train()\n","        costs = []\n","\n","        for step, batch in enumerate(train_dataloader):\n","            batch = tuple(t.cuda() for t in batch)\n","\n","            # labels : (batch_size, max_length) -> (batch_size*max_length, )\n","            inputs, input_lengths, labels = batch\n","\n","            # hypothesis : (batch_size, max_length, number_of_labels) -> (batch_size*max_length, number_of_labels)\n","            hypothesis = model(inputs)\n","\n","            cost = loss_func(hypothesis.reshape(-1, len(label2idx)), labels.flatten())\n","\n","            ''' Eg. hypothesis.reshape(-1, len(label2idx))의 과정\n","                :  batch_size=2, max_length=2, number_of_labels(len(label2idx))=3\n","\n","                hypothesis =\n","                [\n","                    [  # 첫 번째 배치\n","                        [0.1, 0.7, 0.2],  # 첫 번째 위치의 예측 확률\n","                        [0.6, 0.2, 0.2],  # 두 번째 위치의 예측 확률\n","                    ],\n","                    [  # 두 번째 배치\n","                        [0.3, 0.4, 0.3],  # 첫 번째 위치의 예측 확률\n","                        [0.8, 0.1, 0.1],  # 두 번째 위치의 예측 확률\n","                    ]\n","                ]\n","\n","                reshaped_hypothesis =\n","                [\n","                    [0.1, 0.7, 0.2],  # 첫 번째 배치, 첫 번째 위치\n","                    [0.6, 0.2, 0.2],  # 첫 번째 배치, 두 번째 위치\n","                    [0.3, 0.4, 0.3],  # 두 번째 배치, 첫 번째 위치\n","                    [0.8, 0.1, 0.1]   # 두 번째 배치, 두 번째 위치\n","                ]\n","\n","                -> 각 배치의 모든 위치에 대한 예측 결과를 담게 됨\n","            '''\n","\n","            ''' flatten 함수\n","                - 다차원 공간 배열을 1차원으로 평탄화해주는 함수\n","\n","                Eg.\n","                labels =\n","                [\n","                    [1, 0],  # 첫 번째 배치의 레이블 (첫 번째, 두 번째 위치)\n","                    [2, 1]   # 두 번째 배치의 레이블 (첫 번째, 두 번째 위치)\n","                ]\n","\n","                flattened_labels = [1, 0, 2, 1]\n","            '''\n","\n","            cost.backward()\n","\n","            optimizer.step()\n","\n","            costs.append(cost.data.item())\n","\n","        torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}_pt\".format(epoch+1)))\n","\n","        print(\"Average Cost : {}\".format(np.mean(costs)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CR_al7_xH6s"},"outputs":[],"source":["def make_sentence(inputs, predicts, labels, idx2eumjeol, idx2label):\n","    predict_sentence, correct_sentence = \"\", \"\"\n","\n","    for index in range(len(inputs)):\n","        eumjeol = idx2eumjeol[inputs[index]]\n","        correct_label = idx2label[labels[index]]\n","        predict_label = idx2label[predicts[index]]\n","\n","        if index == 0:\n","            predict_sentence += eumjeol\n","            correct_sentence += eumjeol\n","            continue\n","\n","        if predict_label == \"B\":\n","            predict_sentence += \" \"\n","        predict_sentence += eumjeol\n","\n","        if correct_label == \"B\":\n","            correct_sentence += \" \"\n","        correct_sentence += eumjeol\n","\n","    return predict_sentence, correct_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wU5MofuB4w8u"},"outputs":[],"source":["def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpHx1CqG42uy"},"outputs":[],"source":["def test(config):\n","    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config)\n","\n","    test_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n","    test_dataloader = DataLoader(test_features, shuffle=True, batch_size=1)\n","\n","    model = SpacingRNN(config).cuda()\n","\n","    model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"])))\n","\n","    total_hypothesis, total_labels = [], []\n","\n","    for step, batch in enumerate(test_dataloader):\n","        model.eval()\n","\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        inputs, input_lengths, labels = batch\n","\n","        hypothesis = model(inputs)\n","\n","        hypothesis = torch.argmax(hypothesis, dim=-1)\n","\n","        input_length = tensor2list(input_lengths[0])\n","        input = tensor2list(inputs[0])[:input_length]\n","        label = tensor2list(labels[0])[:input_length]\n","        hypothesis = tensor2list(hypothesis[0])[:input_length]\n","\n","        total_hypothesis += hypothesis\n","        total_labels += label\n","\n","        if step < 10:\n","            predict_sentence, correct_sentence = make_sentence(input, hypothesis, label, idx2eumjeol, idx2label)\n","            print(\"정답 : \" + correct_sentence)\n","            print(\"출력 : \" + predict_sentence)\n","            print()\n","\n","    print(\"Accuracy : {}\".format(accuracy_score(total_labels, total_hypothesis)))"]},{"cell_type":"markdown","metadata":{"id":"Zx_zkwZR7QGN"},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2McHKGOZ84Zl","outputId":"72e4216a-6fae-49c3-9a97-eda2f272c9b2"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-10-1efc284bc4bf>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"])))\n"]},{"name":"stdout","output_type":"stream","text":["정답 : 은숙도 오빠도 그때부터 과외공부를 했다.\n","출력 : 은 숙도 오빠도 그 때부터 과 외공부를 했다.\n","\n","정답 : 레이첼:\n","출력 : 레 이첼:\n","\n","정답 : 내가 일어서자 정화가 따라서 일어났다.\n","출력 : 내가 일어서 자정화가 따라서 일어났다.\n","\n","정답 : 우선 수운과 해월의 사상은 그 뿌리를 전통 유교에 두고 있는 것으로 생각되는데, 동학은 개혁 유교 학자에 따라서는 세속화된 유교라고 보는 시각도 있다라고 볼 수 있을 정도로 교리가 전통 유교, 그 중에서도 성리학과 관계되는 경우가 많았다.\n","출력 : 우선 수운과 해 월의 사상은 그 뿌리를 전통 유교에 두고 있는 것으로 생각되는데, 동학은 개혁 유 교학자에 따라서는 세속화된 유교라고 보는 시각도 있다라고 볼 수 있을 정도로 교리가 전통 유교, 그중에서도 성리학과 관계되는 경우가 많았다.\n","\n","정답 : \"그것만은 확실하게 맹세할 수 있어.\"\n","출력 : \"그 것만은 확실하게 맹세할 수 있어.\"\n","\n","정답 : \"얼굴이 왜 그래?\"\n","출력 : \"얼굴이 왜 그래?\"\n","\n","정답 : 뒤집으면 영어로 같은 것들이 인쇄되어 있었다.\n","출력 : 뒤집으면 영어로 같은 것들이인 쇄되어 있었다.\n","\n","정답 : 강한섭이 키스를 하거나 그녀의 몸을 패팅할 때면 그녀는 온 몸이 뜨겁게 달았다.\n","출력 : 강한섭 이 키스를 하거나 그녀의 몸을 패팅할 때면 그녀는 온몸이 뜨 겁게 달았다.\n","\n","정답 : \"친구집에 있는다고 어제 연락은 해뒀었어요.\"\n","출력 : \"친 구 집에 있는다고 어제 연락은 해뒀었어요.\"\n","\n","정답 : 다시 수건을 뭉쳐서 민신혜의 입 속으로 쑤셔넣었다.\n","출력 : 다시 수건을 뭉쳐서 민신혜의 입속으로 쑤셔 넣었다.\n","\n","Accuracy : 0.9197536873874312\n"]}],"source":["if(__name__==\"__main__\"):\n","    root_dir = \"/content/drive/MyDrive/연구실/기계학습/rnn\"\n","    output_dir = os.path.join(root_dir, \"scaling_rnn_output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\"mode\": \"train\",\n","              \"model_name\":\"epoch_5_pt\",\n","              \"input_data\":os.path.join(root_dir, \"train.txt\"),\n","              \"output_dir\":output_dir,\n","              \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n","              \"label_vocab\": os.path.join(root_dir, \"label_vocab.txt\"),\n","              \"eumjeol_vocab_size\": 2458,\n","              \"embedding_size\": 100,\n","              \"hidden_size\": 100,\n","              \"max_length\": 920,\n","              \"number_of_labels\": 3,\n","              \"epoch\":5,\n","              \"batch_size\":64,\n","              \"dropout\":0.3\n","              }\n","\n","    if(config[\"mode\"] == \"test\"):\n","        train(config)\n","    else:\n","        test(config)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPW2aG4RAxmufCy9yHMDnAC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}